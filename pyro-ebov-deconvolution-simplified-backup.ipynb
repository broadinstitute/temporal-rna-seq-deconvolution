{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hindu-curtis",
   "metadata": {},
   "source": [
    "## Ebola infected Macaque Sample Composition Trajectory Identification\n",
    "\n",
    "```\n",
    "Indices:\n",
    "\n",
    "- c cell type\n",
    "- g genes\n",
    "- m samples\n",
    "- k deformation polynomial degree\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pylab as plt\n",
    "import matplotlib\n",
    "import matplotlib.pyplot\n",
    "from typing import Dict\n",
    "from pyro.distributions.torch_distribution import TorchDistribution, TorchDistributionMixin\n",
    "from torch.distributions.utils import probs_to_logits, logits_to_probs, broadcast_all, lazy_property\n",
    "from torch.distributions import constraints\n",
    "import torch\n",
    "import pyro\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from typing import List, Dict\n",
    "from boltons.cacheutils import cachedproperty\n",
    "from pyro.distributions.torch_distribution import TorchDistribution, TorchDistributionMixin\n",
    "from torch.distributions.utils import probs_to_logits, logits_to_probs, broadcast_all, lazy_property\n",
    "from torch.distributions import constraints\n",
    "from numbers import Number\n",
    "import pyro.distributions as dist\n",
    "import anndata\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures, SplineTransformer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-honolulu",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time_deconv.time_deconv import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-trustee",
   "metadata": {},
   "source": [
    "## Parameter Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-indianapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "dtype = torch.float32\n",
    "dtype_np = np.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-satellite",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-castle",
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_anndata_path = \"/home/nbarkas/disk2/deconvolution_method/datasets/ebov/load_data_python/ebov_bulk.h5ad\"\n",
    "sc_anndata_path = \"/home/nbarkas/disk2/deconvolution_method/datasets/ebov/load_data_python/ebov_sc.h5ad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-setting",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(bulk_anndata_path, 'rb') as fh:\n",
    "    bulk_anndata  = anndata.read_h5ad(fh)\n",
    "with open(sc_anndata_path, 'rb') as fh:\n",
    "    sc_anndata = anndata.read_h5ad(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-television",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select samples only after or on tp 0\n",
    "bulk_anndata = bulk_anndata[bulk_anndata.obs['dpi_time'] >= 0,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-circus",
   "metadata": {},
   "outputs": [],
   "source": [
    "ebov_dataset = DeconvolutionDataset(\n",
    "    sc_anndata = sc_anndata,\n",
    "    sc_celltype_col = \"Subclustering_reduced\",\n",
    "    bulk_anndata = bulk_anndata,\n",
    "    bulk_time_col = \"dpi_time\",\n",
    "    dtype_np = dtype_np,\n",
    "    dtype = dtype,\n",
    "    device=device,\n",
    "    feature_selection_method = 'overdispersed_bulk_and_high_sc' #'overdispersed_bulk'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-lodging",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv = TimeRegularizedDeconvolution(\n",
    "    dataset=ebov_dataset,\n",
    "    polynomial_degree = 20,\n",
    "    #basis_functions = \"legendre\",\n",
    "    basis_functions = \"polynomial\",\n",
    "    device=device,\n",
    "    dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv.fit_model(n_iters=5_000, verbose=True, log_frequency=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-proceeding",
   "metadata": {},
   "source": [
    "## Examine Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv.calculate_composition_trajectories(n_intervals = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv.plot_composition_trajectories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-knife",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv.plot_phi_g_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-stability",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv.plot_beta_g_distribution()\n",
    "matplotlib.pyplot.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-picnic",
   "metadata": {},
   "source": [
    "# Synthetic dataset generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "  \n",
    "    z = np.exp(-x)\n",
    "    sig = 1 / (1 + z)\n",
    "\n",
    "    return sig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-indianapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_dict = generate_batch(pseudo_time_reg_deconv.dataset, device, dtype)\n",
    "batch_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-species",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sigmoid_proportions(num_cell_types, num_samples, t_m):\n",
    "    # generate the celltype proportions\n",
    "    effect_size = torch.rand(num_cell_types) # 0,1\n",
    "    shift = torch.rand(num_cell_types)\n",
    "    magnitude = torch.where(torch.rand(num_cell_types) < 0.5, -1., 1.)\n",
    "    \n",
    "    # Generate cell population mc\n",
    "    cell_pop_cm = torch.zeros(num_cell_types, num_samples)\n",
    "    for i in range(num_cell_types):\n",
    "        cell_pop_cm[i,:] = torch.Tensor(list(sigmoid(magnitude[i]*x+shift[i]) for x in t_m)) * effect_size[i]\n",
    "    cell_pop_cm = torch.nn.functional.softmax(cell_pop_cm, dim=0)\n",
    "    \n",
    "    return {\n",
    "        \n",
    "        'trajectory_params': {\n",
    "            'type': 'sigmoid',\n",
    "            'effect_size': effect_size,\n",
    "            'shift': shift,\n",
    "            'magnitude': magnitude,\n",
    "            \n",
    "        },\n",
    "        'cell_pop_cm': cell_pop_cm\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-tourist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_with_sigmoid_proportions(start_time = -5, end_time = 5, step = 1, num_samples = 100,\n",
    "                                     lib_size_mean = 1e6, lib_size_std = 2e5, use_betas = False):\n",
    "    \"\"\"Simulate bulk data with compositional changes\"\"\"\n",
    "    \n",
    "    # Discrete timepoints to sample from\n",
    "    xs = torch.arange(start_time, end_time, step)\n",
    "    \n",
    "    # Number of celltypes are same as in main deconvolution\n",
    "    num_cell_types = pseudo_time_reg_deconv.w_hat_gc.shape[1]\n",
    "    \n",
    "    # Sample the times for the samples\n",
    "    t_m = xs[torch.randint(len(xs), (num_samples,))]\n",
    "    \n",
    "    proportions_sample = sample_sigmoid_proportions(num_cell_types, num_samples, t_m)\n",
    "    \n",
    "    cell_pop_cm = proportions_sample['cell_pop_cm']\n",
    "    \n",
    "    # Get phis and betas from main model\n",
    "    # phi_g ~ 0.1 - 0.2\n",
    "    \n",
    "    phi_g = pyro.param(\"log_phi_posterior_loc_g\").detach().exp().cpu()\n",
    "    beta_g = pyro.param(\"log_beta_posterior_loc_g\").detach().exp().cpu()\n",
    "    \n",
    "    # Get celltype profiles from the model\n",
    "    w_hat_gc = pseudo_time_reg_deconv.w_hat_gc.detach().cpu()\n",
    "    if use_betas:\n",
    "        unnorm_w_hat_gc = w_hat_gc * beta_g[:,None]\n",
    "    else:\n",
    "        unnorm_w_hat_gc = w_hat_gc\n",
    "    \n",
    "    # Normalize\n",
    "    w_gc = unnorm_w_hat_gc / unnorm_w_hat_gc.sum(0)\n",
    "    \n",
    "    # Get some library sizes \n",
    "    lib_sizes_m = torch.normal(\n",
    "        mean=torch.full([num_samples], lib_size_mean), \n",
    "        std=torch.full([num_samples], lib_size_std)\n",
    "    )\n",
    "    \n",
    "    # Get the NegBinomial means\n",
    "    # consider: random component on w_gc?\n",
    "    # b_gc -> gene + celltype specific distortion ( how does inference degrade as this increases )\n",
    "    # sample b_gc from laplace (mu = 1, beta(scale) = )\n",
    "    # Gamma(mean = 1, var = 1/rate)\n",
    "    # rate = concentration = a\n",
    "    # 1/a = var of gamma distribution\n",
    "    # sample beta_cg \n",
    "    mu_mg = lib_sizes_m[:,None] * torch.matmul(cell_pop_cm.T, w_gc.transpose(-1, -2))\n",
    "    \n",
    "    # Sample a full matrix using phis from main model\n",
    "    x_ng = NegativeBinomialAltParam(mu=mu_mg, phi = phi_g).sample()\n",
    "    \n",
    "    return {\n",
    "        'cell_pop_cm': cell_pop_cm,\n",
    "        't_m': t_m,\n",
    "        'x_ng': x_ng,\n",
    "        'trajectory_params': proportions_sample['trajectory_params'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-poster",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_simulated_proportions(sim_res):\n",
    "    \"\"\"Plot simulated proportion results\"\"\"\n",
    "    \n",
    "    \n",
    "    fig, ax = matplotlib.pyplot.subplots()\n",
    "    o = torch.argsort(sim_res['t_m'])\n",
    "    ax.plot(sim_res['t_m'][o], sim_res['cell_pop_cm'][:,o].T)\n",
    "    ax.set_title('Simulated proportions')\n",
    "    ax.set_xlabel('Set time')\n",
    "    ax.set_ylabel('Proportions')\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-sally",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_anndata_from_sim(sim_res):\n",
    "    \"\"\"Generate AnnData object from the simulation results\n",
    "    \n",
    "    Time is stored in the time dimension\n",
    "    \"\"\"\n",
    "    \n",
    "    var_tmp = pd.DataFrame({'gene': pseudo_time_reg_deconv.dataset.selected_genes })\n",
    "    var_tmp = var_tmp.set_index('gene')\n",
    "    \n",
    "    return anndata.AnnData(\n",
    "        X = sim_res['x_ng'].numpy(),\n",
    "        var = var_tmp,\n",
    "        obs = pd.DataFrame({'time': sim_res['t_m']})\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-montana",
   "metadata": {},
   "source": [
    "## Evaluate Simulation 1 (100 samples; polynomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-innocent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate and plot proportions\n",
    "sim_res = simulate_with_sigmoid_proportions(num_samples=100)\n",
    "plot_simulated_proportions(sim_res)\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-potato",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_bulk = generate_anndata_from_sim(sim_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "ebov_simulated_dataset = DeconvolutionDataset(\n",
    "    sc_anndata = sc_anndata,\n",
    "    sc_celltype_col = \"Subclustering_reduced\",\n",
    "    bulk_anndata = simulated_bulk,\n",
    "    bulk_time_col = \"time\",\n",
    "    dtype_np = dtype_np,\n",
    "    dtype = dtype,\n",
    "    device = device,\n",
    "    feature_selection_method = 'common' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-agriculture",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv_sim = TimeRegularizedDeconvolution(\n",
    "    dataset=ebov_simulated_dataset,\n",
    "    polynomial_degree = 20,\n",
    "    basis_functions = \"polynomial\",\n",
    "    device=device,\n",
    "    dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv_sim.fit_model(n_iters=20_001, verbose=True, log_frequency=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-advertising",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv_sim.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-school",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv_sim.calculate_composition_trajectories(n_intervals = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-mobility",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_simulated_proportions(sim_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv_sim.plot_composition_trajectories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-johnson",
   "metadata": {},
   "source": [
    "## Polynomial low degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv_sim = TimeRegularizedDeconvolution(\n",
    "    dataset=ebov_simulated_dataset,\n",
    "    polynomial_degree = 5,\n",
    "    #basis_functions = \"legendre\",\n",
    "    basis_functions = \"polynomial\",\n",
    "    device=device,\n",
    "    dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-entertainment",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv_sim.fit_model(n_iters=20_001, verbose=True, log_frequency=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv_sim.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_simulated_proportions(sim_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv_sim.calculate_composition_trajectories(n_intervals = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-master",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv_sim.plot_composition_trajectories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-migration",
   "metadata": {},
   "source": [
    "### With legendre polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv_sim = TimeRegularizedDeconvolution(\n",
    "    dataset=ebov_simulated_dataset,\n",
    "    polynomial_degree = 3,\n",
    "    basis_functions = \"legendre\",\n",
    "    device=device,\n",
    "    dtype=dtype)\n",
    "pseudo_time_reg_deconv_sim.fit_model(n_iters=20_001, verbose=True, log_frequency=1000)\n",
    "pseudo_time_reg_deconv_sim.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv_sim.calculate_composition_trajectories(n_intervals = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_simulated_proportions(sim_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-garbage",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv_sim.plot_composition_trajectories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-piece",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Many ledenre polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-assembly",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv_sim = TimeRegularizedDeconvolution(\n",
    "    dataset=ebov_simulated_dataset,\n",
    "    polynomial_degree = 15,\n",
    "    basis_functions = \"legendre\",\n",
    "    device=device,\n",
    "    dtype=dtype)\n",
    "pseudo_time_reg_deconv_sim.fit_model(n_iters=20_001, verbose=True, log_frequency=1000)\n",
    "pseudo_time_reg_deconv_sim.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-liberal",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv_sim.calculate_composition_trajectories(n_intervals = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-nutrition",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_simulated_proportions(sim_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv_sim.plot_composition_trajectories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-letters",
   "metadata": {},
   "source": [
    "# Without betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-moment",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv_sim = TimeRegularizedDeconvolution(\n",
    "    dataset=ebov_simulated_dataset,\n",
    "    polynomial_degree = 20,\n",
    "    #basis_functions = \"legendre\",\n",
    "    basis_functions = \"polynomial\",\n",
    "    use_betas = False,\n",
    "    device=device,\n",
    "    dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-assurance",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv_sim.fit_model(n_iters=20_001, verbose=True, log_frequency=1000)\n",
    "pseudo_time_reg_deconv_sim.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_simulated_proportions(sim_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv_sim.calculate_composition_trajectories(n_intervals = 1000)\n",
    "pseudo_time_reg_deconv_sim.plot_composition_trajectories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-clinic",
   "metadata": {},
   "source": [
    "## Error Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-space",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-delaware",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_error_L1(sim_res, pseudo_time_reg_deconv_sim, n_intervals = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-gasoline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-ottawa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-renaissance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample on the t_m (LOO or range)\n",
    "# training and generalization accuracy \n",
    "# generalizatoin accuracy vs time\n",
    "# discontiuity and sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-pacific",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and generalization accuracy for different gene and cell distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-writer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-editor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-cedar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-wellington",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-spiritual",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-killing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-mortality",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-breeding",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-original",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-microphone",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
