{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "practical-attitude",
   "metadata": {},
   "source": [
    "# Deconvolve simulated data with linear functions, vary number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ternadecov.simulator import *\n",
    "from ternadecov.time_deconv import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-cycle",
   "metadata": {},
   "source": [
    "# Configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "dtype = torch.float32\n",
    "dtype_np = np.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-integer",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-former",
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_anndata_path = \"/home/nbarkas/disk1/work/deconvolution_method/datasets/ebov/load_data_python/ebov_bulk.h5ad\"\n",
    "sc_anndata_path = \"/home/nbarkas/disk1/work/deconvolution_method/datasets/ebov/load_data_python/ebov_sc.h5ad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-speech",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(bulk_anndata_path, 'rb') as fh:\n",
    "    bulk_anndata  = anndata.read_h5ad(fh)\n",
    "with open(sc_anndata_path, 'rb') as fh:\n",
    "    sc_anndata = anndata.read_h5ad(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select samples only after or on tp 0\n",
    "bulk_anndata = bulk_anndata[bulk_anndata.obs['dpi_time'] >= 0,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "ebov_dataset = DeconvolutionDataset(\n",
    "    sc_anndata = sc_anndata,\n",
    "    sc_celltype_col = \"Subclustering_reduced\",\n",
    "    bulk_anndata = bulk_anndata,\n",
    "    bulk_time_col = \"dpi_time\",\n",
    "    dtype_np = dtype_np,\n",
    "    dtype = dtype,\n",
    "    device=device,\n",
    "    feature_selection_method = 'overdispersed_bulk_and_high_sc' #'overdispersed_bulk'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-prairie",
   "metadata": {},
   "source": [
    "# Run Deconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv = TimeRegularizedDeconvolution(\n",
    "    dataset=ebov_dataset,\n",
    "    polynomial_degree = 10,\n",
    "    basis_functions = \"polynomial\",\n",
    "    device=device,\n",
    "    dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv.fit_model(n_iters=5_001, verbose=True, log_frequency=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-garlic",
   "metadata": {},
   "source": [
    "# Examine Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-closing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the losses\n",
    "pseudo_time_reg_deconv.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and plot composition trajectories\n",
    "pseudo_time_reg_deconv.calculate_composition_trajectories(n_intervals = 1000)\n",
    "pseudo_time_reg_deconv.plot_composition_trajectories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the per-gene dispersions\n",
    "pseudo_time_reg_deconv.plot_phi_g_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-substance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the gene capture coefficients\n",
    "pseudo_time_reg_deconv.plot_beta_g_distribution()\n",
    "matplotlib.pyplot.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-while",
   "metadata": {},
   "source": [
    "# Simulation -- Vary number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-difference",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trajectory generating function\n",
    "trajectory_type = 'periodic'\n",
    "\n",
    "n_samples = list(range(10,100,10)) \n",
    "n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-october",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a single trajectory for all iterations\n",
    "trajectory_coef = sample_trajectories(\n",
    "    type = trajectory_type,\n",
    "    num_cell_types = pseudo_time_reg_deconv.w_hat_gc.shape[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-spirituality",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = []\n",
    "l1_error = []\n",
    "shape_l1_error = []\n",
    "\n",
    "a = 10\n",
    "\n",
    "for n in n_samples:\n",
    "    \n",
    "    sim_res = simulate_data(\n",
    "        num_samples=n, \n",
    "        num_cell_types = pseudo_time_reg_deconv.dataset.num_cell_types,\n",
    "        num_genes = pseudo_time_reg_deconv.dataset.num_genes,\n",
    "        w_hat_gc = torch.Tensor(pseudo_time_reg_deconv.dataset.w_hat_gc),\n",
    "        trajectory_type=trajectory_type, \n",
    "        dirichlet_alpha = a,\n",
    "        trajectory_coef = trajectory_coef\n",
    "    )\n",
    "    \n",
    "    plot_simulated_proportions(sim_res)\n",
    "    \n",
    "    simulated_bulk = generate_anndata_from_sim(\n",
    "        sim_res, \n",
    "        reference_deconvolution=pseudo_time_reg_deconv)\n",
    "    \n",
    "    ebov_simulated_dataset = DeconvolutionDataset(\n",
    "        sc_anndata = sc_anndata,\n",
    "        sc_celltype_col = \"Subclustering_reduced\",\n",
    "        bulk_anndata = simulated_bulk,\n",
    "        bulk_time_col = \"time\",\n",
    "        dtype_np = dtype_np,\n",
    "        dtype = dtype,\n",
    "        device = device,\n",
    "        feature_selection_method = 'common' \n",
    "    )\n",
    "    \n",
    "    pseudo_time_reg_deconv_sim = TimeRegularizedDeconvolution(\n",
    "        dataset=ebov_simulated_dataset,\n",
    "        polynomial_degree = 10,\n",
    "        basis_functions = \"polynomial\",\n",
    "        device=device,\n",
    "        dtype=dtype)\n",
    "    \n",
    "    pseudo_time_reg_deconv_sim.fit_model(n_iters=3_001, verbose=True, log_frequency=1000)\n",
    "    \n",
    "    errors = calculate_prediction_error(sim_res, pseudo_time_reg_deconv_sim)\n",
    "    \n",
    "    df_n.append(n)\n",
    "    l1_error.append(errors['L1_error_norm'])\n",
    "    shape_l1_error.append(errors['shape_L1_error'])\n",
    "    \n",
    "    pseudo_time_reg_deconv_sim.plot_composition_trajectories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot L1 loss\n",
    "error_df = pd.DataFrame({'n':df_n, 'l1': list(x.item() for x in l1_error)})\n",
    "error_df.plot(x='n',y='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-television",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Dirichlet alpha values\n",
    "\n",
    "alphas = list(pseudo_time_reg_deconv.param_store_hist[i]['dirichlet_alpha'] for i in range(len(pseudo_time_reg_deconv.param_store_hist)))\n",
    "\n",
    "matplotlib.pyplot.plot(alphas[-500:])\n",
    "matplotlib.pyplot.title(r'Dirichlet $ \\alpha $ Values')\n",
    "matplotlib.pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
