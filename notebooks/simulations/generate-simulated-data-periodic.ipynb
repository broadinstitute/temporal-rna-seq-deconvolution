{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "recovered-geology",
   "metadata": {},
   "source": [
    "# Generate Simulated Data and Save to Disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eaae4e-ceb4-4679-8d57-3d887c162085",
   "metadata": {},
   "source": [
    "In this tutorial notebook we illustrate how to generate a simulated dataset and deconvolve it back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nutritional-focus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load imports\n",
    "\n",
    "import torch\n",
    "import anndata\n",
    "import matplotlib.pylab as plt\n",
    "import torch\n",
    "from ternadecov.simulator import *\n",
    "from ternadecov.time_deconv import *\n",
    "from ternadecov.time_deconv import *\n",
    "from ternadecov.simulator import *\n",
    "from ternadecov.stats_helpers import *\n",
    "from ternadecov.dataset import *\n",
    "from ternadecov.deconvolution_plotter import *\n",
    "from ternadecov.parametrization import *\n",
    "from ternadecov.deconvolution_writer import DeconvolutionWriter\n",
    "from ternadecov.deconvolution_exporter import DeconvolutionExporter\n",
    "from ternadecov.deconvolution_plotter import DeconvolutionPlotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "thousand-raise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set general configuration\n",
    "device = torch.device(\"cuda:0\")\n",
    "dtype = torch.float32\n",
    "dtype_np = np.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-magnitude",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "geological-grocery",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to set attribute `.var` of view, copying.\n"
     ]
    }
   ],
   "source": [
    "location_fascicularis = '/home/nbarkas/disk2/deconvolution_method/datasets/nhp_fascicularis_atlas/h5ad/'\n",
    "\n",
    "h5ad_paths = {\n",
    "    # Ebov Datasets\n",
    "    \"bulk_blood\": \"ebov_bulk.h5ad\",\n",
    "    \"sc_blood\": \"/home/nbarkas/disk2/deconvolution_method/datasets/ebov/load_data_python/ebov_sc.h5ad\",\n",
    "    \"bulk_all\": \"/home/nbarkas/disk2/deconvolution_method/datasets/ebov/all_ebov_bulk.h5ad\",\n",
    "    \n",
    "    \n",
    "    # fascicularis\n",
    "    \"sc_adrenal\": f\"{location_fascicularis}/Adrenal_gland.h5ad\",\n",
    "    \"sc_cerebellum\": f\"{location_fascicularis}/Cerebellum.h5ad\",\n",
    "    \"sc_kidney\": f\"{location_fascicularis}/Kidney.h5ad\",\n",
    "    \"sc_liver\": f\"{location_fascicularis}/Liver.h5ad\",\n",
    "    \"sc_lung\": f\"{location_fascicularis}/Lung.h5ad\",\n",
    "    \"sc_lymph_node\": f\"{location_fascicularis}/Lymph_node.h5ad\",\n",
    "    \"sc_neocortex\": f\"{location_fascicularis}/Neocortex.h5ad\",\n",
    "    \"sc_pbmc\": f\"{location_fascicularis}/PBMC.h5ad\",\n",
    "    \"sc_skin\": f\"{location_fascicularis}/Skin.h5ad\",\n",
    "    \"sc_spleen\": f\"{location_fascicularis}/Spleen.h5ad\",\n",
    "    \"sc_subcutaneous_adipose\": f\"{location_fascicularis}/Subcutaneous_adipose.h5ad\",\n",
    "    \"sc_testis\": f\"{location_fascicularis}/Testis.h5ad\",\n",
    "    \"sc_thyroid\": f\"{location_fascicularis}/Thyroid_gland.h5ad\",\n",
    "    \"sc_uterus\": f\"{location_fascicularis}/Uterus.h5ad\",\n",
    "    \"sc_vagina\": f\"{location_fascicularis}/Vagina.h5ad\",\n",
    "}\n",
    "\n",
    "with open(h5ad_paths['bulk_all'], 'rb') as fh:\n",
    "    all_bulk_anndata = anndata.read_h5ad(fh)\n",
    "    \n",
    "with open(h5ad_paths['sc_pbmc'], 'rb') as fh:\n",
    "    sc_anndata = anndata.read_h5ad(fh)\n",
    "    \n",
    "all_bulk_anndata = all_bulk_anndata[all_bulk_anndata.obs['dpi_time'] >=0,]\n",
    "all_bulk_anndata = all_bulk_anndata[all_bulk_anndata.obs['full.tissue'] == 'Whole blood',]\n",
    "\n",
    "all_bulk_anndata.var.gene = all_bulk_anndata.var.gene.astype(str)\n",
    "all_bulk_anndata.var = all_bulk_anndata.var.set_index('gene')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682ce679-7264-4b6d-8c4e-0f0951c30e24",
   "metadata": {},
   "source": [
    "## First deconvolve existing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adf795a-d405-4c2d-a4cc-f825fc995089",
   "metadata": {},
   "source": [
    "We start by deconvolving an existing dataset using the single-cell reference we will use for the simulation. This allows for the estimation of parameters that go into the simulation directly from the dataset (such as gene dispersions and gene capture rates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "coupled-exception",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_sc_cutoff: 2\n",
      "3097 genes selected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbarkas/disk1/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.32118e-10): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True,\n"
     ]
    }
   ],
   "source": [
    "# setup the datatypes for the deconvolution to defaults (e.g float32) \n",
    "datatype_param = DeconvolutionDatatypeParametrization()\n",
    "\n",
    "# setup the deconvolution dataset\n",
    "ebov_dataset = DeconvolutionDataset(\n",
    "    types=datatype_param,\n",
    "    parametrization = DeconvolutionDatasetParametrization(\n",
    "        # Single-cell dataset parameters\n",
    "        sc_anndata = sc_anndata,\n",
    "        sc_celltype_col = \"Abbreviation\",\n",
    "        # Bulk dataset parameters\n",
    "        bulk_anndata = all_bulk_anndata,\n",
    "        bulk_time_col = \"dpi_time\",\n",
    "        # Method for selecting genes to use\n",
    "        feature_selection_method = 'overdispersed_bulk_and_high_sc'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "injured-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we deconvolve using the gp method\n",
    "pseudo_time_reg_deconv = TimeRegularizedDeconvolutionModel(\n",
    "    dataset=ebov_dataset,\n",
    "    trajectory_model_type='gp', # Use gaussian process\n",
    "    hyperparameters=TimeRegularizedDeconvolutionModelParametrization(), # default\n",
    "    trajectory_hyperparameters=TimeRegularizedDeconvolutionGPParametrization(), # default\n",
    "    types=datatype_param\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-victorian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 0, time: 1 s ] loss: 29320539.56\n",
      "[step: 1000, time: 25 s ] loss: 8005712.57\n",
      "[step: 2000, time: 49 s ] loss: 3322621.49\n",
      "[step: 3000, time: 74 s ] loss: 1896432.99\n",
      "[step: 4000, time: 98 s ] loss: 1346338.18\n",
      "[step: 5000, time: 123 s ] loss: 1081510.72\n",
      "[step: 6000, time: 148 s ] loss: 946770.23\n",
      "[step: 7000, time: 173 s ] loss: 875150.99\n",
      "[step: 8000, time: 198 s ] loss: 835369.71\n",
      "[step: 9000, time: 224 s ] loss: 812767.66\n"
     ]
    }
   ],
   "source": [
    "n_iters = 20_000\n",
    "pseudo_time_reg_deconv.fit_model(n_iters=n_iters, verbose=True, log_frequency=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-source",
   "metadata": {},
   "source": [
    "# Examine Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-significance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the losses\n",
    "plotter = DeconvolutionPlotter(pseudo_time_reg_deconv)\n",
    "plotter.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-success",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and plot composition trajectories\n",
    "plotter.plot_composition_trajectories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-command",
   "metadata": {},
   "source": [
    "## Simulate New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate and plot 100 samples from a random trajectory \n",
    "# based on linear functions through a softmax\n",
    "\n",
    "sim_res = simulate_data(\n",
    "    w_hat_gc = torch.Tensor(pseudo_time_reg_deconv.dataset.w_hat_gc),\n",
    "    num_samples=100, \n",
    "    trajectory_type='periodic',\n",
    "    start_time = -5.,\n",
    "    end_time = 5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e501405-8cf6-4164-b4c2-1e5b8af1df70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fcb9d1-0bd6-49bb-af0e-6740d8828183",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.min(sim_res['t_m']).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c87cf4f-be8c-465d-8f0c-e3f5c5426c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "#plot_simulated_proportions(sim_res, ebov_dataset)\n",
    "#matplotlib.pyplot.tight_layout()\n",
    "#matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97df8272-dbfa-4fd5-82bd-719fc7708478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate input AnnData object from the above simulation\n",
    "simulated_bulk = generate_anndata_from_sim(\n",
    "    sim_res, \n",
    "    reference_dataset = ebov_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ca6598-3b6a-4ed4-85a0-6fac692ad8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the newly simulated bulk data to disk\n",
    "simulated_bulk.write('simulated_bulk_pbmc.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434396e3-a01a-4b15-888f-285c832db4f3",
   "metadata": {},
   "source": [
    "## Deconvolve the simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-testing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a deconvolution dataset\n",
    "ebov_simulated_dataset = DeconvolutionDataset(\n",
    "    types=datatype_param,\n",
    "    parametrization = DeconvolutionDatasetParametrization(\n",
    "        sc_anndata = sc_anndata,\n",
    "        sc_celltype_col = \"Abbreviation\",\n",
    "        bulk_anndata = simulated_bulk,\n",
    "        bulk_time_col = \"time\",\n",
    "        feature_selection_method = 'overdispersed_bulk_and_high_sc'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422470b2-bc8d-4a77-9252-cff308a11000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up and run the deconvolution\n",
    "pseudo_time_reg_deconv_sim = TimeRegularizedDeconvolutionModel(\n",
    "    dataset=ebov_simulated_dataset,\n",
    "    trajectory_model_type='gp',\n",
    "    hyperparameters=TimeRegularizedDeconvolutionModelParametrization(),\n",
    "    trajectory_hyperparameters=TimeRegularizedDeconvolutionGPParametrization(),\n",
    "    types=datatype_param\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-jefferson",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv_sim.fit_model(\n",
    "    n_iters=5_001, \n",
    "    verbose=True, \n",
    "    log_frequency=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-clause",
   "metadata": {},
   "source": [
    "# Examine Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ce71cf-1e8d-4e44-b397-1fbc7d88f6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ternadecov.deconvolution_plotter import DeconvolutionPlotter\n",
    "plotter = DeconvolutionPlotter(pseudo_time_reg_deconv_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeaff72-5604-44f5-9ec6-c2b2dcac8411",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fa24ac-b9c1-4bfe-942a-b131a11d1203",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.plot_composition_trajectories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22443239-fcbf-4d6d-bbef-ef85492b9552",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
