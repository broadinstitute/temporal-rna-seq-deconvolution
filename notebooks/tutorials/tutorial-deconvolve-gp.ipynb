{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "recovered-geology",
   "metadata": {},
   "source": [
    "# Tutorial: Deconvolving with GP model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e242bd-fc89-4f61-b393-84f6f68b9fb3",
   "metadata": {},
   "source": [
    "Ternadecov is a python package for deconvolving time series Bulk RNA-seq datasets. By simulteneously attempting to identify an underlying trajectory of sample composition change and estimate individual sample composition it can more efficiently share information between successive samples and inform about the underlying process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de38e966-ba33-4cd7-bc0f-65126eb73eab",
   "metadata": {},
   "source": [
    "In this tutorial we will be deconvolving a bulk data set using the Gaussian Process trajectory model and generating all possible output plots as well as extracting calculated sample and trajectory values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9182dc-c0dc-40d4-a3e0-d6fb3b92e229",
   "metadata": {},
   "source": [
    "## Initialize\n",
    "We first load the required libraries and set a global configuration that we will need later. This includes the number of iterations we want to run in our training loop and initializing a `DeconvolutionDatatypeParametrization` object that holds the datatypes we will be using for the deconvolution.\n",
    "\n",
    "The recommended number of iterations for deconvolution is >20,000, however for brevity of execution we here use a smaller number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nutritional-focus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import \n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ternadecov.simulator import *\n",
    "from ternadecov.time_deconv import *\n",
    "from ternadecov.time_deconv import *\n",
    "from ternadecov.simulator import *\n",
    "from ternadecov.stats_helpers import *\n",
    "from ternadecov.dataset import *\n",
    "from ternadecov.deconvolution_plotter import *\n",
    "from ternadecov.parametrization import *\n",
    "from ternadecov.evaluation import evaluate_with_trajectory\n",
    "from ternadecov.deconvolution_writer import DeconvolutionWriter\n",
    "from ternadecov.deconvolution_exporter import DeconvolutionExporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "thousand-raise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure\n",
    "n_iters = 5_000\n",
    "datatype_param = DeconvolutionDatatypeParametrization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cec38f-499e-4e0e-948c-67e519dacabc",
   "metadata": {},
   "source": [
    "### Optionally log more information\n",
    "We can optionally log more information by setting the log-level to info\n",
    "\n",
    "`logging.basicConfig(encoding='utf-8', level=logging.INFO)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-magnitude",
   "metadata": {},
   "source": [
    "### Load data\n",
    "Next we load the datasets that we will use. We need two datasets, both in AnnData format. One dataset will be the bulk RNA-seq dataset that we want to deconvolve. This dataset must have a column under .obs that provides the time at which each particular sample is collected. The name of this column doesn't matter as it can be specified while configuring the deconvolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "geological-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to h5ad files containing the AnnData object\n",
    "sc_anndata_path = \"/home/nbarkas/disk2/deconvolution_method/datasets/ebov/load_data_python/ebov_sc.h5ad\"\n",
    "bulk_anndata_path = 'simulated_linear.h5ad'\n",
    "\n",
    "# load the files -- this take a while\n",
    "with open(bulk_anndata_path, 'rb') as fh:\n",
    "    bulk_anndata  = anndata.read_h5ad(fh)\n",
    "with open(sc_anndata_path, 'rb') as fh:\n",
    "    sc_anndata = anndata.read_h5ad(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66266993-4370-474d-93c7-9f2d6e609ceb",
   "metadata": {},
   "source": [
    "### Perform deconvolution\n",
    "Next we perform the deconvolution. The first step to performing the deconvolution is to generate a `DeconvolutionDataset` object. This object contains all input data to the deconvolution, including the single-cell used as reference and bulk data we are deconvolving. The object is also responsible for selecting the genes that we will use for the deconvolution at the next step. The most important parameter to specify here is `feature_selection_method` that defines the algorithm that is used to select genes. In general we want to use maximally informative genes in both datasets. \n",
    "\n",
    "The `common` method used below uses all genes that are present in both datasets. It is generally not suitable for deconvolution except for the case of simulated datasets (as we have here). If in doubt do not specify the value and allow the default `overdispersed_bulk_and_high_sc` to be selected. In this mode genes that are both overdispersed in the bulk and also hightly expressed in the single-cell data are used. The cutoffs for both over-dispersion and high expression can be manually specified. Consult the object documentation for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "geological-testing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12180 genes selected\n"
     ]
    }
   ],
   "source": [
    "ebov_simulated_dataset = DeconvolutionDataset(\n",
    "    types=datatype_param,\n",
    "    parametrization = DeconvolutionDatasetParametrization(\n",
    "        sc_anndata = sc_anndata,\n",
    "        sc_celltype_col = \"Subclustering_reduced\",\n",
    "        bulk_anndata = bulk_anndata,\n",
    "        bulk_time_col = \"time\",\n",
    "        feature_selection_method = 'common'\n",
    "    )       \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bbf810-5cc8-403d-a064-53091fd6bcfd",
   "metadata": {},
   "source": [
    "Next we generate a `TimeRegularizedDeconvolutionModel`, which is the object that will perform the deconvolution. In additoion to the dataset generated above we need to specify parameters indicating what trajectory model for deconvolution we should want to use. In this case we are using a gaussian process model by seeting `trajectory_model_type = 'gp'`. Different trajectory model types require different sets of paraters, the required ones for GP deconvolution are specified here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c8979b8-8227-4e41-8def-ff859d4f5bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv_sim = TimeRegularizedDeconvolutionModel(\n",
    "    dataset=ebov_simulated_dataset,\n",
    "    trajectory_model_type='gp',\n",
    "    hyperparameters=TimeRegularizedDeconvolutionModelParametrization(),\n",
    "    trajectory_hyperparameters=TimeRegularizedDeconvolutionGPParametrization(),\n",
    "    types=datatype_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc92da06-cdbe-401b-a242-d0335120fdaf",
   "metadata": {},
   "source": [
    "Finally we execute the training loop by calling `.fit_model()` with the desired number of iterations. If we want to continue previous training we can set `clear_param_store` to False and continue the training we hve already started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-jefferson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 0, time: 1 s ] loss: 7152810.43\n",
      "[step: 1000, time: 69 s ] loss: 5351101.71\n",
      "[step: 2000, time: 138 s ] loss: 4575175.73\n",
      "[step: 3000, time: 206 s ] loss: 4270728.48\n",
      "[step: 4000, time: 276 s ] loss: 4163041.57\n"
     ]
    }
   ],
   "source": [
    "pseudo_time_reg_deconv_sim.fit_model(\n",
    "    n_iters=n_iters, \n",
    "    verbose=True, \n",
    "    log_frequency=1000,\n",
    "    clear_param_store = True,\n",
    "    keep_param_store_history=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-clause",
   "metadata": {},
   "source": [
    "### Examine Outputs\n",
    "Next we want to examine the outputs of our deconvolution. `ternadecov` provides two object classes for viewing and examing the data the `DeconvolutionPlotter` and the `DeconvolutionWriter`. The former object generates (and saves) plots while the latter outputs and saves data in tabular format.\n",
    "\n",
    "We start by making a `DeconvolutionPlotter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5b4e77-c4ad-4c49-a375-a1a7c2952c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = DeconvolutionPlotter(pseudo_time_reg_deconv_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c878b8ae-dc0a-42b8-b1ba-5d8cbbc6ecb6",
   "metadata": {},
   "source": [
    "First we plot the loss as a function of the training iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-commitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the losses\n",
    "plotter.plot_loss()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b689638-fa89-4c3c-8c02-df1cbea584be",
   "metadata": {},
   "source": [
    "Next we plot the distribution of the $phi_g$ values. These are the gene-specific dispersion values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the per-gene dispersions\n",
    "plotter.plot_phi_g_distribution()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5358dc1-89a3-48eb-9d66-27b4115c10c9",
   "metadata": {},
   "source": [
    "Next we plot the distibution of the $\\beta_g$ values. These are gene-specific capture rates for the single-cell data reference generration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the gene-specific capture rates\n",
    "plotter.plot_beta_g_distribution()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f616247b-b0d2-45ac-9152-2663ad056e0d",
   "metadata": {},
   "source": [
    "We can now generate a plot of sample-specific compositons in scatter format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot samples specific compositions in scatter format\n",
    "plotter.plot_sample_compositions_scatter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f8cf79-1f62-493a-8c44-7ccc3f9e2b18",
   "metadata": {},
   "source": [
    "A better way to examine the output trajectories is to directly draw trajectory samples from the posterior. This allows us to ascertain the confidence in the trajectory estimation. The following function draws samples form the posterior and calculates IQR ranges of the trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acf7460-bd31-45bb-9830-97c580073f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.plot_composition_trajectories_via_posterior_sampling(figsize=(7.0,7.0),show_combined=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed567b2-e7c0-41dd-a871-916d73b94152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A different parametrization of the sample function will provide a combined plot\n",
    "plotter.plot_composition_trajectories_via_posterior_sampling(\n",
    "    figsize=(7.0,7.0),\n",
    "    show_combined=True,\n",
    "    show_iqr=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba1d110-4f38-4f67-bf59-9bfac0694c0e",
   "metadata": {},
   "source": [
    "The following function provides an alternative way of plotting the GP trajectory data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be53290a-b449-4253-85cf-6b8431fa19d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.plot_gp_composition_trajectories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56069da4-ae10-43f1-bde0-c6f56ddaf3a3",
   "metadata": {},
   "source": [
    "In addition to plotting trajectories we can directly plot posterior estimates for individual samples. the following function provides posterior estimates for the composition of each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6c5264-c304-45e0-a7d9-8c2153a6b031",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.plot_sample_compositions_boxplot_confidence()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50e3ff4-2c27-4618-82a6-e81c53faf063",
   "metadata": {},
   "source": [
    "Alternatively we can plot point estimates for the composition of each sample as a boxplot. In this particular dataset where we only have one sample at each time point this plot is not very informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe09610-a606-4c36-81e5-1a37a0768864",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.plot_sample_compositions_boxplot()\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d2c8b9-137e-42ec-8c63-a3cefae2c51d",
   "metadata": {},
   "source": [
    "An alternative way plotting composition trajectories is by directly plotting the mean trajectory from the GP (as opposed the the mean of samples). This is less noisy that the plot above, buyt does not provide and information on the error estimates of each plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9896032a-a516-40a7-9477-1ca1edae9339",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.plot_composition_trajectories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00384ae-1fba-4429-a3b4-16bfaf978c4c",
   "metadata": {},
   "source": [
    "### Summarizing cell types into super-groups\n",
    "In some cases we want to be able to summarize different celltypes together. An example of this is to summarize tissue specific vs tissue infiltrating cells or generalize our annotation to general scale cell-types and avoid the confusion be excessive granularity. \n",
    "\n",
    "In order to do this we need to define a custom cell type summarization map, as well as a custom color scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd55a2ef-0655-4b0d-b29e-8855bdd6545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "celltype_summarization = {\n",
    "    'typeA': ('B','Mono','NK','Neut'),\n",
    "    'typeB': ('Plasmablast','Tc','Th','cDC','pDC')\n",
    "}\n",
    "\n",
    "colors = {'typeA': 'red', 'typeB': 'blue'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42cc783-3ae9-4c13-a064-cde4d1227a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.plot_summarized_cell_compositions(celltype_summarization = celltype_summarization, )\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9d66c2-2dcf-469d-ae41-8afca8fbe7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.plot_composition_trajectories_via_posterior_sampling(\n",
    "    iqr_alpha=0.2,\n",
    "    show_combined=True,\n",
    "    ncols=3,\n",
    "    lw=2.,\n",
    "    figsize=(6,6),\n",
    "    sharey=False,\n",
    "    celltype_summarization=celltype_summarization,\n",
    "    cell_type_to_color_dict = colors,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731efc27-4727-4bbf-98fe-ef47d12568ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter.plot_composition_trajectories_via_posterior_sampling(\n",
    "    iqr_alpha=0.2,\n",
    "    show_combined=False,\n",
    "    ncols=3,\n",
    "    lw=2.,\n",
    "    figsize=(6,6),\n",
    "    sharey=False,\n",
    "    celltype_summarization=celltype_summarization,  \n",
    "    cell_type_to_color_dict = colors,     \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35adfa0b-f358-4659-b2c2-a82515afec95",
   "metadata": {},
   "source": [
    "### Extracting values\n",
    "Finally, we may wish to extract specific estimates from the deconvolution. We can do this with the help of the `DeconvolutionWriter`, which can both return data in tabular (usually pandas) format, or write them to disk using the `filename` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc5dc36-e58a-4e56-bee3-77939e4fd350",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = DeconvolutionWriter(pseudo_time_reg_deconv_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0ec493-97ad-44bb-a022-1725d140f81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.write_summarized_cell_compositions(\n",
    "    return_table = True,\n",
    "    celltype_summarization=celltype_summarization\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642bc7b7-b70c-424e-8781-347ab057b654",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.write_cell_compositions(return_table = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5d102d-ff92-4d80-bcd3-67504ab92e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.write_sample_draws_quantiles(return_table = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c380a6-9fef-4289-a589-7fab0767cd68",
   "metadata": {},
   "source": [
    "# Exporting all outputs\n",
    "Finally it is possible to export all the results from ternadecov using the `DeconvolutionExporter` object. This object uses the plotter and writer above to generate all available plots and save the in a specified directory with minimal user intervention. Consult the manual of the `DeconvolutionExporter` object for more information on how to use it."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
