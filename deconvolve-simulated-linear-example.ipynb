{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "recovered-geology",
   "metadata": {},
   "source": [
    "# Deconvolving simulated data generated with linear functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nutritional-focus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from time_deconv.time_deconv_simulator import *\n",
    "from time_deconv.time_deconv import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-signal",
   "metadata": {},
   "source": [
    "# Configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "thousand-raise",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "dtype = torch.float32\n",
    "dtype_np = np.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-magnitude",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "geological-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_anndata_path = \"/home/nbarkas/disk1/work/deconvolution_method/datasets/ebov/load_data_python/ebov_bulk.h5ad\"\n",
    "sc_anndata_path = \"/home/nbarkas/disk1/work/deconvolution_method/datasets/ebov/load_data_python/ebov_sc.h5ad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "meaning-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(bulk_anndata_path, 'rb') as fh:\n",
    "    bulk_anndata  = anndata.read_h5ad(fh)\n",
    "with open(sc_anndata_path, 'rb') as fh:\n",
    "    sc_anndata = anndata.read_h5ad(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "spare-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select samples only after or on tp 0\n",
    "bulk_anndata = bulk_anndata[bulk_anndata.obs['dpi_time'] >= 0,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-dallas",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "interstate-earthquake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CCNF', 'TEDC2', 'NAGA', 'NEURL3', 'BET1', 'PTPRC', 'EMC7', 'KATNBL1',\n",
       "       'CCDC86', 'PTGDR2',\n",
       "       ...\n",
       "       'NRAS', 'IGFBP6', 'BOLA3', 'GPR162', 'CIB2', 'BEX3', 'ZNF614', 'STUB1',\n",
       "       'IER5L', 'AMMECR1L'],\n",
       "      dtype='object', name='gene', length=12180)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bulk_anndata.var.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "stone-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_genes = list(('CCNF', 'TEDC2', 'NAGA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "super-voluntary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CCNF', 'TEDC2', 'NAGA']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "composite-nightmare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_anndata.var.index.isin(selected_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "answering-rolling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View of AnnData object with n_obs × n_vars = 56929 × 3\n",
       "    obs: 'X', 'batch', 'DPI', 'DPIc', 'Period', 'full_sample_id', 'frz_status', 'sample_source', 'sample', 'array_num', 'array_id', 'animal', 'full_dash_status', 'dash_status', 'sample_dash', 'Barcode', 'BP', 'FullSeqRun', 'n_counts', 'n_genes', 'log_count', 'batch_short', 'PCT_USABLE_BASES', 'PCT_MRNA_BASES', 'EBOV_counts', 'num_EBOV_genes', 'percent_EBOV', 'EBOV_TPT', 'log10_EBOV_TPT', 'percent_mito', 'PCT_UNUSABLE_BASES', 'percent_ribo', 'percent_hbb', 'leiden', 'leiden_lab_orig', 'leiden_lab_orig_group', 'leiden_lab_2', 'leiden_lab_group_2', 'SubclusteringGroup', 'Subclustering', 'Doublet', 'Subclustering_reduced', 'Soup_Usage', 'ebola_infection_threshold', 'Ebola_Positive', 'sampleID'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_anndata[:, selected_genes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "coupled-exception",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=3.1044e-10): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of selected_genes: <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "ebov_dataset = DeconvolutionDataset(\n",
    "    sc_anndata = sc_anndata,\n",
    "    sc_celltype_col = \"Subclustering_reduced\",\n",
    "    bulk_anndata = bulk_anndata,\n",
    "    bulk_time_col = \"dpi_time\",\n",
    "    dtype_np = dtype_np,\n",
    "    dtype = dtype,\n",
    "    device=device,\n",
    "    feature_selection_method = 'overdispersed_bulk_and_high_sc' #'overdispersed_bulk'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-forge",
   "metadata": {},
   "source": [
    "# Run Deconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "injured-scientist",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-622f582511e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbasis_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"polynomial\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     dtype=dtype)\n\u001b[0m",
      "\u001b[0;32m/mnt/disk2/nbarkas/deconvolution_method/temporal-rna-seq-deconvolution/time_deconv/time_deconv.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, basis_functions, polynomial_degree, device, dtype, use_betas)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# cache useful tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_hat_gc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_hat_gc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     def model(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "pseudo_time_reg_deconv = TimeRegularizedDeconvolution(\n",
    "    dataset=ebov_dataset,\n",
    "    polynomial_degree = 5,\n",
    "    basis_functions = \"polynomial\",\n",
    "    device=device,\n",
    "    dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-victorian",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv.fit_model(n_iters=5_001, verbose=True, log_frequency=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-source",
   "metadata": {},
   "source": [
    "# Examine Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-significance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the losses\n",
    "pseudo_time_reg_deconv.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-success",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and plot composition trajectories\n",
    "pseudo_time_reg_deconv.calculate_composition_trajectories(n_intervals = 1000)\n",
    "pseudo_time_reg_deconv.plot_composition_trajectories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the per-gene dispersions\n",
    "pseudo_time_reg_deconv.plot_phi_g_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-fisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the gene capture coefficients\n",
    "pseudo_time_reg_deconv.plot_beta_g_distribution()\n",
    "matplotlib.pyplot.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-command",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate and plot 100 samples from a random trajectory \n",
    "# based on linear functions through a softmax\n",
    "\n",
    "sim_res = simulate_data(\n",
    "    num_samples=100, \n",
    "    reference_deconvolution=pseudo_time_reg_deconv, \n",
    "    trajectory_type='linear')\n",
    "\n",
    "plot_simulated_proportions(sim_res)\n",
    "matplotlib.pyplot.tight_layout()\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-testing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate input AnnData object from the above simulation\n",
    "simulated_bulk = generate_anndata_from_sim(\n",
    "    sim_res, \n",
    "    reference_deconvolution = pseudo_time_reg_deconv)\n",
    "\n",
    "# Generate a deconvolution dataset\n",
    "ebov_simulated_dataset = DeconvolutionDataset(\n",
    "    sc_anndata = sc_anndata,\n",
    "    sc_celltype_col = \"Subclustering_reduced\",\n",
    "    bulk_anndata = simulated_bulk,\n",
    "    bulk_time_col = \"time\",\n",
    "    dtype_np = dtype_np,\n",
    "    dtype = dtype,\n",
    "    device = device,\n",
    "    feature_selection_method = 'common' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-jefferson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up and run the deconvolution\n",
    "pseudo_time_reg_deconv_sim = TimeRegularizedDeconvolution(\n",
    "    dataset=ebov_simulated_dataset,\n",
    "    polynomial_degree = 20,\n",
    "    basis_functions = \"polynomial\",\n",
    "    device=device,\n",
    "    dtype=dtype)\n",
    "\n",
    "pseudo_time_reg_deconv_sim.fit_model(\n",
    "    n_iters=5_001, \n",
    "    verbose=True, \n",
    "    log_frequency=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-clause",
   "metadata": {},
   "source": [
    "# Examine Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-commitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv_sim.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_time_reg_deconv_sim.calculate_composition_trajectories(n_intervals = 1000)\n",
    "pseudo_time_reg_deconv_sim.plot_composition_trajectories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the per-gene dispersions\n",
    "pseudo_time_reg_deconv.plot_phi_g_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the gene capture coefficients\n",
    "pseudo_time_reg_deconv.plot_beta_g_distribution()\n",
    "matplotlib.pyplot.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the alphas\n",
    "\n",
    "alphas = list(pseudo_time_reg_deconv.param_store_hist[i]['dirichlet_alpha'] for i in range(len(pseudo_time_reg_deconv.param_store_hist)))\n",
    "\n",
    "fig, ax = matplotlib.pyplot.subplots(1,2)\n",
    "\n",
    "ax[0].plot(alphas)\n",
    "ax[0].set_title(r'Dirichlet $ \\alpha $ Values')\n",
    "\n",
    "ax[1].plot(alphas[-500:])\n",
    "ax[1].set_title(r'Last few Dirichlet $ \\alpha $ Values')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-comment",
   "metadata": {},
   "source": [
    "## Evaluate with variable alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-madonna",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_vals = list(10**(x -1 ) for x in range(4)) \n",
    "alpha_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a single trajectory for all iterations\n",
    "trajectory_coef = sample_linear_trajectories(num_cell_types = pseudo_time_reg_deconv.w_hat_gc.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = []\n",
    "l1_error = []\n",
    "\n",
    "for a in alpha_vals:\n",
    "    sim_res = simulate_data(\n",
    "        num_samples=100, \n",
    "        reference_deconvolution=pseudo_time_reg_deconv, \n",
    "        trajectory_type='linear', \n",
    "        dirichlet_alpha = a,\n",
    "        trajectory_coef = trajectory_coef\n",
    "    )\n",
    "    \n",
    "    plot_simulated_proportions(sim_res)\n",
    "    \n",
    "    simulated_bulk = generate_anndata_from_sim(sim_res, reference_deconvolution=pseudo_time_reg_deconv)\n",
    "    \n",
    "    ebov_simulated_dataset = DeconvolutionDataset(\n",
    "        sc_anndata = sc_anndata,\n",
    "        sc_celltype_col = \"Subclustering_reduced\",\n",
    "        bulk_anndata = simulated_bulk,\n",
    "        bulk_time_col = \"time\",\n",
    "        dtype_np = dtype_np,\n",
    "        dtype = dtype,\n",
    "        device = device,\n",
    "        feature_selection_method = 'common' \n",
    "    )\n",
    "    \n",
    "    pseudo_time_reg_deconv_sim = TimeRegularizedDeconvolution(\n",
    "        dataset=ebov_simulated_dataset,\n",
    "        polynomial_degree = 3,\n",
    "        basis_functions = \"polynomial\",\n",
    "        device=device,\n",
    "        dtype=dtype)\n",
    "    \n",
    "    pseudo_time_reg_deconv_sim.fit_model(n_iters=5_001, verbose=True, log_frequency=1000)\n",
    "    \n",
    "    errors = calculate_prediction_error(sim_res, pseudo_time_reg_deconv_sim)\n",
    "    df_a.append(a)\n",
    "    l1_error.append(errors['L1_error_norm'])\n",
    "    \n",
    "    pseudo_time_reg_deconv_sim.plot_composition_trajectories()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
